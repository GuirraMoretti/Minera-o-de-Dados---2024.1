{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/paulotguerra/QXD0178/blob/main/00.01-Introducao-Jupyter-NumPy-Pandas.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QXD0178 - Mineração de Dados\n",
    "# Pré-processamento de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Professor:** Paulo de Tarso Guerra Oliveira ([paulodetarso@ufc.br](mailto:paulodetarso@ufc.br))\n",
    "\n",
    "Parcialmente adaptado de: [*Introdução à Mineração de Dados: Conceitos Básicos, Algoritmos e Aplicações.*](https://app.minhabiblioteca.com.br/reader/books/978-85-472-0100-5/pageid/45) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpeza de dados**\n",
    "\n",
    "O primeiro passo é verificar se a base necessita de algum procedimento de limpeza de dados. \n",
    "\n",
    "Alguns objetos podem ter informações faltantes. Uma das opções é eliminar esses objetos, reduzindo o tamanho da base; contudo, a remoção pode causar perda de informação importante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Valores ausentes**\n",
    "Um valor ausente costuma ser representado por um código de ausência, que pode ser um valor específico, um espaço em branco ou um símbolo (por exemplo, ''np.NaN''). Um valor ausente caracteriza um valor ignorado ou que não foi observado, e, nesse sentido, a substituição de valores ausentes, também conhecida como imputação, tem como objetivo estimar os valores ausentes com base nas informações disponíveis no conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A imputação de valores ausentes assume que essa ausência de valor implica a perda de informação relevante de algum atributo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os métodos tradicionais de imputação de valores ausentes são:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  **Ignorar o objeto**: consiste em remover da base (ignorar) todos aqueles objetos que possuem um ou mais valores ausentes. \n",
    "2. **Imputar manualmente os valores ausentes**: consiste em escolher de forma empírica um valor a ser imputado para cada valor ausente.\n",
    "3. **Usar uma constante global para imputar o valor ausente**: ecorresponde a substituir todos os valores ausentes de certo atributo por uma constante única. \n",
    "4. **Imputação do tipo hot-deck**: um valor ausente é imputado usando o valor do mesmo atributo de um objeto similar aleatoriamente selecionado. \n",
    "5. **Imputar de acordo com a última observação (last observation carried forward)**: consiste em ordenar a base de dados seguindo um ou mais de seus atributos e então busca cada valor ausente e usa aquele valor da célula imediatamente anterior para imputar o valor ausente.\n",
    "6. **Usar a média ou moda de um atributo para imputar o valor ausente**: o método consiste em substituir os valores ausentes de cada atributo pela média (no caso de atributos numéricos) ou moda (no caso de atributos nominais) dos valores do atributo.\n",
    "7. **Usar a média ou moda de todos os objetos da mesma classe para imputar o valor ausente**: a diferença deste método para o anterior é que a média ou moda é tomada considerando apenas os objetos da mesma classe daquele que contém o valor ausente.\n",
    "8. **Usar modelos preditivos para imputar o valor ausente**: qualquer método preditivo pode ser usado para estimar o valor ausente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma abordagem mais sistemática de tratamento de valores ausentes deve considerar quatro passos:\n",
    "\n",
    "* investigar as razões dos dados ausentes de forma que os evite; \n",
    "* investigar o impacto dos dados ausentes no resultado das análises a serem feitas em termos de confiabilidade, validade e generalização das conclusões;\n",
    "* considerar os vários métodos de imputação de valores ausentes; e \n",
    "* investigar o resultado da aplicação de cada um dos métodos considerados no passo anterior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redução de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Redução dos dados**\n",
    "\n",
    "A redução dos dados tem como um dos objetivos a construção de bases de dados menores para aumento do desempenho computacional, ao mesmo tempo que tenta manter as características originais dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O aumento do número de objetos e da dimensão do espaço (número de atributos na base) pode fazer com que os dados disponíveis se tornem esparsos e as medidas matemáticas usadas na análise tornem-se numericamente instáveis. . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além disso, uma quantidade muito grande de objetos e atributos pode tornar o processamento dos algoritmos de mineração muito complexo, assim como os modelos gerados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As técnicas de redução de dados podem ser aplicadas tanto para reduzir a quantidade de objetos da base quanto para reduzir a quantidade de atributos que os descrevem (dimensionalidade),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentre os métodos de redução de dados destacam-se:\n",
    "\n",
    "* **Seleção de atributos (ou características)**: efetua uma redução de dimensionalidade na qual atributos irrelevantes, pouco relevantes ou redundantes são detectados e removidos.\n",
    "* **Compressão de atributos**: também efetua uma redução da dimensionalidade, mas empregando algoritmos de codificação ou transformação de dados (atributos), em vez de seleção.\n",
    "* **Redução no número de dados**: neste método, os dados são removidos, substituídos ou estimados por representações menores (mais simples), como modelos paramétricos (que armazenam apenas os parâmetros do modelo em vez dos dados) e os métodos não paramétricos, como agrupamento, amostragem e histogramas.\n",
    "* **Discretização**: os valores de atributos são substituídos por intervalos ou níveis conceituais mais elevados, reduzindo a quantidade final de atributos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redução do número de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métodos de **amostragem** tem como objetivo selecionar um subconjunto de objetos de uma base que seja representativo de toda ela para efeitos de análise ou estudo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os principais métodos de amostragem são:\n",
    "* **Amostragem aleatória sem substituição**: uma amostra com $n$ objetos distintos $(n < N)$ é retirada aleatoriamente da base de dados.\n",
    "* **Amostragem aleatória com substituição**: similar ao caso anterior, mas cada objeto retirado da base é armazenado e devolvido à base, de forma que ele possa ser selecionado novamente.\n",
    "* **Amostragem sistemática**: consiste em organizar a base de dados seguindo algum critério, por exemplo, do menor ao maior valor de algum atributo do objeto ou do objeto mais antigo ao mais novo, e selecionar objetos de forma sistemática, como por exemplo, os objetos cujos índices são pares ou apenas os objetos gerados no ano atual.\n",
    "* **Amostragem por grupo**: se uma base de dados está agrupada em M grupos disjuntos, então $m$ grupos $(m < M)$ podem ser escolhidos aleatoriamente.\n",
    "* **Amostragem estratificada**: se a base de dados está dividida em grupos ou classes, então na amostragem estratificada a proporção de dados de cada classe é mantida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vantagem da amostragem é que seu custo computacional é proporcional ao tamanho da amostra a ser retirada da base e, portanto, é sublinear em relação ao tamanho original da base. \n",
    "\n",
    "A principal desvantagem do método é o possível erro do processo de mineração por causa da amostragem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressão de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As técnicas de compressão aplicam uma codificação ou transformação para que uma representação compacta dos dados ou atributos originais seja obtida.\n",
    "Se os dados originais puderem ser reconstruídos a partir dos dados comprimidos sem perda de informação, então dizemos que o método de compressão é sem perda (*lossless*); senão, dizemos que é com perda (*lossy*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **análise de componentes principais** (*Principal Component Analysis* – PCA), um dos métodos mais úteis e eficazes na compressão de dados, é um procedimento estatístico que converte um conjunto de objetos com atributos possivelmente correlacionados em um conjunto de objetos com atributos linearmente descorrelacionados, chamados de compo-nentes principais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A análise de componentes principais é a principal técnica linear para a redução de dimensionalidade dos dados. Ela realiza um mapeamento linear (também chamado de projeção) dos dados em um espaço de dimensão menor, a fim de que a variância dos dados nesse espaço seja maximizada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos de aproximação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os *modelos de aproximação* de dados operam de forma completamente diferente dos métodos amostrais, e seu objetivo é representar ou ajustar os dados usando algum modelo que pode ser definido ou não por um conjunto de parâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformação**\n",
    "\n",
    "Os métodos de transformação de dados visam modificar ou consolidar os dados em formas apropriadas aos processos de mineração. Por exemplo, pode haver valores de um mesmo atributo escritos em maiúsculo e outros em minúsculo, e os formatos e as unidades podem ser diferentes. Problemas dessa natureza são resolvidos padronizando ou normalizando os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronização\n",
    "\n",
    "O objetivo principal da padronização é resolver as diferenças de unidades e escalas dos dados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Capitalização**: dados nominais podem aparecer em minúsculo, maiúsculo ou ambos. Para evitar inconsistências com ferramentas sensíveis a letras maiúsculas ou minúsculas, é usual padronizar as fontes, normalmente para maiúsculo.\n",
    "* **Caracteres especiais**: algumas ferramentas de mineração de dados podem ser sensíveis ao conjunto de caracteres utilizado em determinado idioma. Por exemplo, ferramentas projetadas para bases de dados na língua inglesa podem apresentar problemas decorrentes da acentuação utilizada na língua portuguesa. Uma simples troca de letras em valores nominais pode evitar eventuais problemas.\n",
    "* **Padronização de formatos**: o uso de alguns tipos de atributos, como datas e números de documentos, permite diferentes formatos. Por exemplo, datas podem ser apresentadas DDMMAAAA ou MMDDAAAA (dependendo do país de origem), um número de CPF pode ser apresentado como XXX.XXX.XXX-XX ou como XXXXXXXXXXX. Para evitar esses problemas, é preciso observar e padronizar o formato de cada atributo da base, principalmente quando diferentes bases precisam ser integradas.\n",
    "* **Conversão de unidades**: outro problema comum nas bases brutas é o uso de diferentes unidades de medida – por exemplo, centímetros ou metros, quilômetros por hora ou milhas por hora etc. Nesse caso, vale o mesmo princípio discutido anteriormente: todos os dados devem ser convertidos e padronizados em uma mesma unidade de medida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização \n",
    "\n",
    "A normalização é um processo de transformação dos dados que objetiva torná-los mais apro-priados à aplicação de algum algoritmo de mineração, como redes neurais artificiais ou méto-dos baseados em distância. A necessidade de normalização pode ser consequência de diversos fatores, como evitar a saturação dos neurônios em uma rede neural artificial de múltiplas ca-madas e fazer com que cada atributo dos dados de entrada tenha o mesmo domínio. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalização Max-Min \n",
    "\n",
    "A normalização Max-Min realiza uma transformação linear nos dados originais. Assuma que $max_a$ e $min_a$ são, respectivamente, os valores máximo e mínimo de determinado\n",
    "atributo $a$. A normalização max-min mapeia um valor a em um valor $a'$ no domínio $[novo\\_{}min_a, novo\\_{}max_a]$, de acordo com seguinte equação:\n",
    "\n",
    "$$a' = \\frac{a - min_a}{max_a - min_a} (novo\\_{}max_a - novo\\_{}min_a) + novo\\_{}min_a$$\n",
    "\n",
    "A aplicação mais frequente dessa normalização é colocar todos os atributos de uma base de dados sob um mesmo intervalo de valores, por exemplo no intervalo [0, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalização pelo z-score\n",
    "\n",
    "Também conhecida por normalização de média zero, os valores de um atributo $a$ são normalizados tendo como base a média e o desvio padrão de $a$, \n",
    "\n",
    "$$a' = \\frac{(a - \\overline{a})}{\\sigma_a}$$\n",
    "\n",
    "onde $\\overline{a}$ é a média e $\\sigma_a$ o desvio padrão de $a$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalização pelo escalonamento decimal \n",
    "\n",
    "A normalização pelo escalonamento decimal move a casa decimal dos valores do atributo $a$. O número de casas decimais movidas depende do valor máximo absoluto do atributo $a$. \n",
    "\n",
    "$$ a' = \\frac{a}{10^j} $$\n",
    "\n",
    "onde $j$ é o menor inteiro tal que $|a'| < 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalização pelo interquartil \n",
    "\n",
    "A normalização interquartil toma cada valor do atributo, subtrai a mediana e divide pelo intervalo interquartil (IQR, do inglês $interquartile range$). \n",
    "\n",
    "Os quartis de um atributo ordenado são os três pontos que dividem o domínio do atributo em quatro grupos de cardinalidades iguais, cada qual composto por um quarto da quantidade total de dados.\n",
    "\n",
    "* O primeiro quartil, $Q_1$ é definido como o ponto central entre o menor valor e a mediana;\n",
    "* O segundo quartil, $Q_2$, é a mediana, que divide o conjunto de dados ordenados em dois subconjuntos, cada um contendo metade da quantidade total dos dados;\n",
    "* O terceiro quartil, $Q_3$, é o valor do meio entre a mediana e o maior valor do atributo.\n",
    "\n",
    "A normalização interquartil opera de acordo com a seguinte equação:\n",
    "\n",
    "$$ a' = \\frac{a - Q_2}{Q_3 - Q_1} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discretização**\n",
    "\n",
    "Muitos algoritmos em mineração de dados não trabalham com dados mistos, ou seja, bases de dados com atributos categóricos e contínuos.\n",
    "\n",
    "Nesses casos, atributos numéricos podem ser discretizados, dividindo o domínio do atributo em intervalos e ampliando a quantidade de métodos de análise disponíveis para aplicação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além disso, a discretização reduz a quantidade de valores de um dado atributo contínuo, facilitando, em muitos casos, o processo de mineração.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maneira mais óbvia de discretizar um certo atributo é dividindo seu domínio em um número predeterminado de intervalos iguais, o que normalmente é feito no momento da coleta dos dados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encaixotamento (*binning*)\n",
    "Atributos podem ser discretizados distribuindo-se seus valores em intervalos (*bins*) e substituindo-se o valor de cada intervalo pela média ou mediana. \n",
    "\n",
    "Há  dois tipos de métodos de encaixotamento: de mesma largura (o intervalo de cada caixa tem o mesmo tamanho) e de mesma frequência (a quantidade de objetos em cada caixa é a mesma). \n",
    "\n",
    "Em ambos os casos, o método de encaixotamento funciona da seguinte maneira: (1) ordene os valores do atributo, (2) defina a quantidade de caixas, (3) escolha um ou mais valores representativos daquela caixa e (4) substi-tua todos os valores da caixa por esses valores. \n",
    "\n",
    "O valor representativo pode ser calculado de diferentes maneiras, por exemplo, pela média ou moda da caixa, ou pelos valores extremos da caixa, sendo que, neste último, cada valor dentro da caixa é substituído pelo extremo mais próximo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogramas\n",
    "\n",
    "Similar à discretização por encaixotamento, a discretização por histogramas utiliza faixas para definir os intervalos de valores do atributo. Após a definição do histograma, os valores do atributo são substituídos de acordo com a faixa na qual estes se encontram; com isso, a quantidade de valores discretos dependerá da quantidade de faixas escolhidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrupamentos\n",
    "\n",
    "Algoritmos de agrupamento são utilizados para particionar o atributo em grupos de valores seguindo um critério preestabelecido. Cada grupo de valores é representado por um protótipo que é utilizado em substituição aos valores que pertencem ao grupo, e diferentes métodos de agrupamento podem ser utilizados para realização dessa tarefa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo de Preparação de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**: [Food choices: College students' food and cooking preferences](https://www.kaggle.com/datasets/borapajo/food-choices?select=food_coded.csv)\n",
    "\n",
    "Esta base de dados inclui informações sobre escolhas alimentares, nutrição, preferências, favoritos da infância e outras informações de estudantes universitários. Existem 126 respostas de alunos. Os dados são brutos e não limpos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>Gender</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>calories_chicken</th>\n",
       "      <th>calories_day</th>\n",
       "      <th>calories_scone</th>\n",
       "      <th>coffee</th>\n",
       "      <th>comfort_food</th>\n",
       "      <th>comfort_food_reasons</th>\n",
       "      <th>comfort_food_reasons_coded</th>\n",
       "      <th>...</th>\n",
       "      <th>soup</th>\n",
       "      <th>sports</th>\n",
       "      <th>thai_food</th>\n",
       "      <th>tortilla_calories</th>\n",
       "      <th>turkey_calories</th>\n",
       "      <th>type_sports</th>\n",
       "      <th>veggies_day</th>\n",
       "      <th>vitamins</th>\n",
       "      <th>waffle_calories</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315.0</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>we dont have comfort</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>345</td>\n",
       "      <td>car racing</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>chocolate, chips, ice cream</td>\n",
       "      <td>Stress, bored, anger</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>frozen yogurt, pizza, fast food</td>\n",
       "      <td>stress, sadness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>500</td>\n",
       "      <td>none</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>I'm not answering this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pizza, Mac and cheese, ice cream</td>\n",
       "      <td>Boredom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>Not sure, 240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ice cream, chocolate, chips</td>\n",
       "      <td>Stress, boredom, cravings</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Softball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>760</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>wine. mac and cheese, pizza, ice cream</td>\n",
       "      <td>boredom and sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Softball</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>2.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pizza / Wings / Cheesecake</td>\n",
       "      <td>Loneliness / Homesick / Sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>basketball</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1315</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>3.882</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1</td>\n",
       "      <td>rice, potato, seaweed soup</td>\n",
       "      <td>sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>580.0</td>\n",
       "      <td>690</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1315</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mac n Cheese, Lasagna, Pizza</td>\n",
       "      <td>happiness, they are some of my favorite foods</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Chocolates, pizza, and Ritz.</td>\n",
       "      <td>hormones, Premenstrual syndrome.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>725.0</td>\n",
       "      <td>345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>575</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GPA  Gender  breakfast  calories_chicken  calories_day  calories_scone  \\\n",
       "0      2.4       2          1               430           NaN           315.0   \n",
       "1    3.654       1          1               610           3.0           420.0   \n",
       "2      3.3       1          1               720           4.0           420.0   \n",
       "3      3.2       1          1               430           3.0           420.0   \n",
       "4      3.5       1          1               720           2.0           420.0   \n",
       "..     ...     ...        ...               ...           ...             ...   \n",
       "120    3.5       1          1               610           4.0           420.0   \n",
       "121      3       1          1               265           2.0           315.0   \n",
       "122  3.882       1          1               720           NaN           420.0   \n",
       "123      3       2          1               720           4.0           420.0   \n",
       "124    3.9       1          1               430           NaN           315.0   \n",
       "\n",
       "     coffee                             comfort_food  \\\n",
       "0         1                                     none   \n",
       "1         2              chocolate, chips, ice cream   \n",
       "2         2          frozen yogurt, pizza, fast food   \n",
       "3         2         Pizza, Mac and cheese, ice cream   \n",
       "4         2             Ice cream, chocolate, chips    \n",
       "..      ...                                      ...   \n",
       "120       2  wine. mac and cheese, pizza, ice cream    \n",
       "121       2               Pizza / Wings / Cheesecake   \n",
       "122       1               rice, potato, seaweed soup   \n",
       "123       1             Mac n Cheese, Lasagna, Pizza   \n",
       "124       2             Chocolates, pizza, and Ritz.   \n",
       "\n",
       "                              comfort_food_reasons  \\\n",
       "0                            we dont have comfort    \n",
       "1                             Stress, bored, anger   \n",
       "2                                  stress, sadness   \n",
       "3                                          Boredom   \n",
       "4                       Stress, boredom, cravings    \n",
       "..                                             ...   \n",
       "120                           boredom and sadness    \n",
       "121                Loneliness / Homesick / Sadness   \n",
       "122                                        sadness   \n",
       "123  happiness, they are some of my favorite foods   \n",
       "124               hormones, Premenstrual syndrome.   \n",
       "\n",
       "     comfort_food_reasons_coded  ...  soup  sports  thai_food  \\\n",
       "0                           9.0  ...   1.0     1.0          1   \n",
       "1                           1.0  ...   1.0     1.0          2   \n",
       "2                           1.0  ...   1.0     2.0          5   \n",
       "3                           2.0  ...   1.0     2.0          5   \n",
       "4                           1.0  ...   1.0     1.0          4   \n",
       "..                          ...  ...   ...     ...        ...   \n",
       "120                         NaN  ...   1.0     1.0          5   \n",
       "121                         NaN  ...   1.0     NaN          4   \n",
       "122                         NaN  ...   1.0     2.0          5   \n",
       "123                         NaN  ...   2.0     2.0          1   \n",
       "124                         NaN  ...   1.0     2.0          2   \n",
       "\n",
       "    tortilla_calories  turkey_calories  type_sports veggies_day  vitamins  \\\n",
       "0              1165.0              345   car racing           5         1   \n",
       "1               725.0              690  Basketball            4         2   \n",
       "2              1165.0              500         none           5         1   \n",
       "3               725.0              690          NaN           3         1   \n",
       "4               940.0              500     Softball           4         2   \n",
       "..                ...              ...          ...         ...       ...   \n",
       "120             940.0              500     Softball           5         1   \n",
       "121             940.0              500  basketball            5         2   \n",
       "122             580.0              690         none           4         2   \n",
       "123             940.0              500          NaN           3         1   \n",
       "124             725.0              345          NaN           4         2   \n",
       "\n",
       "     waffle_calories                    weight  \n",
       "0               1315                       187  \n",
       "1                900                       155  \n",
       "2                900  I'm not answering this.   \n",
       "3               1315             Not sure, 240  \n",
       "4                760                       190  \n",
       "..               ...                       ...  \n",
       "120             1315                       156  \n",
       "121             1315                       180  \n",
       "122             1315                       120  \n",
       "123             1315                       135  \n",
       "124              575                       135  \n",
       "\n",
       "[125 rows x 61 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/She-Codes-Now/Intro-to-Data-Science-with-R/master/food_coded.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformação de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capitalização\n",
    "\n",
    "# Caracteres especiais\n",
    "\n",
    "# Padronização de formatos\n",
    "\n",
    "# Conversão de unidades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização Min-Max\n",
    "\n",
    "# Normalização z-score\n",
    "\n",
    "# Normalização por escala decimal\n",
    "\n",
    "# Normalização interquartil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encaixotamento \n",
    "\n",
    "# Histograma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
